{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install reverse_geocoder\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import reverse_geocoder as rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "#  df_ts_complete: df with values where time series is complete\n",
    "#  df_estimate: df where all time series values are NaN but there is an estimate\n",
    "#  df_ts_incomplete: df with values where at least one of time series values is NaN\n",
    "# \n",
    "# Reads global powerplant data data from CSV, drops irrelevant columns, splits df (see output), \n",
    "# and re-indexes df with gppdf_idnr as index\n",
    "def read_clean_and_split():  \n",
    "    df = pd.read_csv(\"..\\data\\global_power_plant_database.csv\")\n",
    "    df_all = df.drop(['country_long', 'name', 'url', 'geolocation_source', 'wepp_id'], axis=1)\n",
    "    \n",
    "    df_ts = (df_all.dropna(how='all', subset=['generation_gwh_2013', 'generation_gwh_2014', 'generation_gwh_2015', 'generation_gwh_2016', 'generation_gwh_2017'])\n",
    "                      .set_index('gppd_idnr'))\n",
    "    df_ts_complete = df_ts.dropna(how='any', subset=['generation_gwh_2013', 'generation_gwh_2014', 'generation_gwh_2015', 'generation_gwh_2016', 'generation_gwh_2017'])\n",
    "    df_estimate = (df_all.dropna(how='any', subset=['estimated_generation_gwh'])\n",
    "                   .set_index('gppd_idnr'))\n",
    "    df_ts_incomplete = df_ts[df_ts[['generation_gwh_2013', 'generation_gwh_2014', 'generation_gwh_2015', 'generation_gwh_2016', 'generation_gwh_2017']].isnull().any(axis=1)]\n",
    "    return df_ts_complete, df_ts_incomplete, df_estimate    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_complete, *_ = read_clean_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_US = df_ts_complete[df_ts_complete['country'] == 'USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds a column with us_state to dataframe df\n",
    "# The used library for reverse geocoding works with K-D trees.\n",
    "# Might produce inaccurate results for border regions\n",
    "def coordinate_to_state(df):\n",
    "    \n",
    "    coordinates = [*zip(df['latitude'], df['longitude'])]\n",
    "    #Uncomment below to include (lat, long) tuple as new column in df\n",
    "    #df.insert(4, 'coordinates', coordinates)\n",
    "\n",
    "    geo_infos = rg.search(tuple(coordinates))\n",
    "\n",
    "    locations = list()\n",
    "\n",
    "    for item in geo_infos:\n",
    "        locations.append(item['admin1'])\n",
    "\n",
    "    df.insert(1, 'us_state', locations)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fixes the obvious mistakes made by coordinate_to_state function\n",
    "# Based on looking up the locations manually\n",
    "def fix_misclassification(df):\n",
    "    #British Columbia\n",
    "    df.at['USA0054249', 'us_state'] = 'Idaho'\n",
    "    df.loc[df['us_state']=='British Columbia', 'us_state'] = 'Washington'\n",
    "    \n",
    "    #Quebec\n",
    "    df.at['USA0056829', 'us_state'] = 'Maine'\n",
    "    df.loc[df['us_state']=='Quebec', 'us_state'] = 'New York'\n",
    "    \n",
    "    #Baja California\n",
    "    df.at['USA0000120', 'us_state'] = 'Arizona'\n",
    "    df.loc[df['us_state']=='Baja California', 'us_state'] = 'California'\n",
    "    \n",
    "    #Ontario \n",
    "    df.at['USA0006369', 'us_state'] = 'Michigan'\n",
    "    df.at['USA0010487', 'us_state'] = 'Minnesota'\n",
    "    df.at['USA0002694', 'us_state'] = 'New York'\n",
    "    \n",
    "    #Chukotskiy Avtonomnyy Okrug\n",
    "    df.loc[df['us_state']=='Chukotskiy Avtonomnyy Okrug', 'us_state'] = 'Alaska'\n",
    "    \n",
    "    #Tamaulipas\n",
    "    df.loc[df['us_state']=='Tamaulipas', 'us_state'] = 'Texas'\n",
    "    \n",
    "    #Yukon\n",
    "    df.loc[df['us_state']=='Yukon', 'us_state'] = 'Alaska'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Y:\\Programme\\anaconda-3\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "coordinate_to_state(df_US)\n",
    "fix_misclassification(df_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California          912\n",
       "New York            327\n",
       "Texas               320\n",
       "Minnesota           255\n",
       "Iowa                213\n",
       "North Carolina      207\n",
       "Michigan            199\n",
       "Pennsylvania        185\n",
       "Illinois            183\n",
       "New Jersey          182\n",
       "Wisconsin           169\n",
       "Massachusetts       160\n",
       "Washington          132\n",
       "Idaho               127\n",
       "Ohio                126\n",
       "Florida             125\n",
       "Alaska              125\n",
       "Oregon              124\n",
       "Colorado            124\n",
       "Kansas              117\n",
       "Virginia            116\n",
       "Georgia             113\n",
       "Indiana             100\n",
       "Missouri             95\n",
       "Arizona              93\n",
       "South Carolina       93\n",
       "Nebraska             90\n",
       "Maine                89\n",
       "Oklahoma             77\n",
       "Connecticut          75\n",
       "Louisiana            75\n",
       "Alabama              72\n",
       "Utah                 67\n",
       "New Mexico           65\n",
       "Nevada               63\n",
       "Maryland             63\n",
       "New Hampshire        60\n",
       "Wyoming              58\n",
       "Vermont              57\n",
       "Tennessee            53\n",
       "Arkansas             52\n",
       "Montana              49\n",
       "North Dakota         43\n",
       "Hawaii               43\n",
       "Kentucky             39\n",
       "Mississippi          37\n",
       "South Dakota         32\n",
       "West Virginia        28\n",
       "Delaware             21\n",
       "Rhode Island         13\n",
       "Washington, D.C.      1\n",
       "Name: us_state, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_US['us_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
